#stream data with kafka producer and pyspark used to consume data, finally display dataframe in console:

step 1:

create topic "demo":

/home/manishmehta/Documents/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic pkttest



step 2:

run producer:


python prodicer_iris.py


step 3:

run consumer:

1> to run consumer_test_v3.py:

/home/manishmehta/Documents/spark-3.3.0-bin-hadoop3/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 spark-consumer_test_v3.py

or 2> consumer_test_v4.py
/home/manishmehta/Documents/spark-3.3.0-bin-hadoop3/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 spark-consumer_test_v4.py

or 3> to run consumer_test_v5.py


python consumer_test_v5.py
